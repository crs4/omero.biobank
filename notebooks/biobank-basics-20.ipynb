{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Loading genotyping data from a ped dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this example is to show how it is possible to load genotyping information held in the pedlink format into omero.biobank.\n",
      "\n",
      "We will first do some experiments with the data, just to understand its structure, and then we will build the appropriate omero.biobank objects.\n",
      "\n",
      "At the end of the exercise, we will show how to extract pedlink files on sub pedigrees and sub set of markers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading the original ped file\n",
      "-----------------------------\n",
      "\n",
      "Some text to describe it?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ped_fname='/var/tmp/T2D_28102013/T2D_28102013_CogoniQC.ped'\n",
      "map_fname='/var/tmp/T2D_28102013/T2D_28102013_CogoniQC.map'\n",
      "fam_fname='/var/tmp/T2D_28102013/T2D_28102013_CogoniQC.fam'\n",
      "pheno_fname='/var/tmp/T2D_28102013/T2DPheno_28102013.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will be using the ped reading utilities present in `bl/vl/genotype/io`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bl.vl.genotype.io import MapReader, PedLineParser\n",
      "import csv\n",
      "\n",
      "class PedReader(object):\n",
      "    def __init__(self, map_fname, ped_fname):\n",
      "        self.map_data = [x for x in MapReader(open(map_fname))]\n",
      "        # we assume 1 column for affection status \n",
      "        # and then len(map_data) markers\n",
      "        dat_types = ['A'] + ['M'] * len(self.map_data)\n",
      "        self.pedline_parser = PedLineParser(dat_types)\n",
      "    def __iter__(self):\n",
      "        labels = [x[1] for x in self.map_data]\n",
      "        with open(ped_fname) as f:\n",
      "            for l in f:\n",
      "                data = self.pedline_parser.parse(l)\n",
      "                yield data[0:6], dict(zip(labels, data[6:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ped_reader = PedReader(map_fname, ped_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, d in enumerate(ped_reader):\n",
      "    if i > 2:\n",
      "        break\n",
      "    print [(k, val) for k, val in d[1].iteritems()][:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('rs7060463', ['G', 'G']), ('rs4668795', ['A', 'A']), ('rs4072683', ['A', 'A'])]\n",
        "[('rs7060463', ['A', 'A']), ('rs4668795', ['C', 'C']), ('rs4072683', ['A', 'A'])]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('rs7060463', ['A', 'A']), ('rs4668795', ['A', 'A']), ('rs4072683', ['A', 'A'])]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next thing, we will check the rs codes against dbSNP139. This is done using an external program/galaxy application. FIXME it would be nice if we could directly invoke a workflow from here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rs_label_fname = '/var/tmp/rs_list.tsv'\n",
      "rs_extra_fname = '/var/tmp/rs_extracted.tsv'\n",
      "with open(rs_label_fname, 'w') as f:\n",
      "    writer = csv.DictWriter(f, fieldnames=['label'], delimiter='\\t')\n",
      "    writer.writeheader()\n",
      "    for r in ped_reader.map_data:\n",
      "        writer.writerow({'label': r[1]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# python ~/work/vs/git/biobank/tools/snp_manager manage_db --db-file dbSNP139.db \\\n",
      "#        --join rs_list.tsv > /var/tmp/extracted.tsv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_rs_labels(fname):\n",
      "    with open(fname) as f:\n",
      "        reader = csv.DictReader(f, delimiter='\\t')\n",
      "        rs_labels = [r['label'] for r in reader]\n",
      "    return rs_labels\n",
      "\n",
      "rs_list = set(read_rs_labels(rs_label_fname))\n",
      "rs_ext  = set(read_rs_labels(rs_extra_fname))\n",
      "len(rs_list), len(rs_ext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(295667, 291634)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears that only a subset of the rs labels actually exists in dbSNP139."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[x for x in (rs_list - rs_ext)][:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "['rs9955474', 'rs6422346', 'rs7393468', 'rs7393469']"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML(\"\"\"<iframe src=http://www.ncbi.nlm.nih.gov/snp/?term=rs6422346 \n",
      "         width=1000 height=400></iframe>\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=http://www.ncbi.nlm.nih.gov/snp/?term=rs6422346 \n",
        "         width=1000 height=400></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<IPython.core.display.HTML at 0x275f510>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One more thing, in `rs_extra_fname` we now have compact `absolute` markers definitions that we will use to define the marker array in omero.biobank."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools as it"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(rs_extra_fname) as f:\n",
      "    for l in it.islice(f, 3):\n",
      "        print l,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "label\tmask\tindex\tpermutation\r\n",
        "rs549\tTATGAACTAAGCGGTGAGGCTCAGGTGGCGGCTCTCGCAGAGCCCCTGATGCTGTTGTTCTTTGAGGGCTTAAGGCCTGATGAACGTAGGCACGTGATGC[A/G]TAATAGTCTTCAATGGTACACTTAACTAGTCTCTTCTGTGTAACAGCAAAAAAAAAAAAAAAAAGAAGAAGAAAGAAAACTGTAGGAAATGTTCTTTTTG\t0\tFalse\r\n",
        "rs699\tTGGATACTAAGTCCTAGGGCCAGAGCCAGCAGAGAGGTTTGCCTTACCTTGGAAGTGGACGTAGGTGTTGAAAGCCAGGGTGCTGTCCACACTGGCTCCC[A/G]TCAGGGAGCAGCCAGTCTTCCATCCTGTCACAGCCTGCATGAACCTGTCAATCTTCTCAGCAGCAACATCCAGTTCTGTGAAGTCCAGAGAGCGTGGGAG\t1\tFalse\r\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The allele order in the mask defines what is the `A` and the `B` alleles. We now need to extract the proper allele order from the masks so that we can properly convert the genotyped values to probabilities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import bl.vl.utils.snp as snp_utils\n",
      "\n",
      "alleles_of_rs = {}\n",
      "ordered_rs_labels = []\n",
      "prob_profiles = []\n",
      "with open(rs_extra_fname) as f:\n",
      "    for r in csv.DictReader(f, delimiter='\\t'):\n",
      "        _, alleles, _ = snp_utils.split_mask(r['mask'])\n",
      "        alleles_of_rs[r['label']] = alleles\n",
      "        ordered_rs_labels.append(r['label'])\n",
      "        prob_profiles.append({(alleles[0], alleles[0]): [1, 0],\n",
      "                              (alleles[0], alleles[1]): [0, 0],\n",
      "                              (alleles[1], alleles[0]): [0, 0],\n",
      "                              (alleles[1], alleles[1]): [0, 1],\n",
      "                              ('0', '0'): [1/3., 1/3.]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this info we can now convert to the gdo (probability arrays) format. \n",
      "FIXME Note that we are setting the confidence to 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_to_array(rs_labels, prob_profiles, data):\n",
      "    N = len(rs_labels)\n",
      "    prob = np.zeros((2, N), dtype=np.float32)\n",
      "    conf = np.zeros((N,), dtype=np.float32)\n",
      "    for i in xrange(N):\n",
      "        prob[:,i] = prob_profiles[i][tuple(data[rs_labels[i]])]\n",
      "    return prob, conf\n",
      "\n",
      "ped_reader = PedReader(map_fname, ped_fname)\n",
      "\n",
      "for r in it.islice(ped_reader, 3):\n",
      "    prob, conf = convert_to_array(ordered_rs_labels, prob_profiles, r[1])\n",
      "    print prob[:,:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0.  1.  1.  0.  1.  0.  0.  1.]\n",
        " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
        "[[ 1.  0.  0.  1.  0.  0.  0.  0.  1.  0.]\n",
        " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  0.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.  1.  0.  1.  0.  0.  0.  1.  0.  0.]\n",
        " [ 0.  0.  1.  0.  0.  0.  1.  0.  1.  0.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now we are ready to upload data into biobank."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Talking to the back-end"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os\n",
      "from bl.vl.kb import KnowledgeBase\n",
      "\n",
      "OME_HOST = os.getenv('OME_HOST', 'localhost')\n",
      "OME_USER = os.getenv('OME_USER', 'test')\n",
      "OME_PASSWD = os.getenv('OME_PASSWD', 'test')\n",
      "CHECK_OME_VERSION = os.getenv('CHECK_OME_VERSION', \"True\") == \"True\"\n",
      "\n",
      "BaseProxy = KnowledgeBase(driver='omero')\n",
      "\n",
      "class Proxy(BaseProxy):\n",
      "  def get_objects_dict(self, klass):\n",
      "    return dict((o.label, o) for o in super(Proxy, self).get_objects(klass))\n",
      "\n",
      "kb = Proxy(OME_HOST, OME_USER, OME_PASSWD, check_ome_version=CHECK_OME_VERSION)\n",
      "kb.connect()\n",
      "kb.start_keep_alive()\n",
      "\n",
      "def cleanup():\n",
      "  print \"# disconnecting the kb\"\n",
      "  kb.disconnect()\n",
      "\n",
      "sys.exitfunc = cleanup\n",
      "\n",
      "print\n",
      "print \"### KB ENV PRELOADED ###\"\n",
      "print \"# connected to %s\" % OME_HOST\n",
      "print \"# knowledge base: kb\"\n",
      "print \"# extra method: kb.get_objects_dict\"\n",
      "print \"########################\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "### KB ENV PRELOADED ###\n",
        "# connected to biobank04.crs4.it\n",
        "# knowledge base: kb\n",
        "# extra method: kb.get_objects_dict\n",
        "########################\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load all the individuals and enroll them in a study"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the following, we will define a new set of individuals and enroll them in a study.\n",
      "Note that studyCode is the code assigned to each individual in a specific study.\n",
      "After the definition, we run a consistency check as follows.\n",
      "*NOTE:* this is not the fastest way to load individuals, see the FIXME importer code for a more efficient implementation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def family_reader(N=None):\n",
      "    fieldnames = ['FID', 'IID', 'Father', 'Mother', 'sex', 'T2D']\n",
      "    reader = csv.DictReader(open(fam_fname), fieldnames=fieldnames, delimiter='\\t')\n",
      "    return reader if N is None else it.islice(reader, 0, N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_family_in_biobank(action, study, reader):\n",
      "    gender_map = {'1': kb.Gender.MALE, '2': kb.Gender.FEMALE}\n",
      "    by_label = {}\n",
      "    for r in reader:\n",
      "        conf = {'gender': gender_map[r['sex']], 'action': action}\n",
      "        if r['Father'] != '0':\n",
      "            conf['father'] = by_label[r['Father']]\n",
      "        if r['Mother'] != '0':\n",
      "            conf['mother'] = by_label[r['Mother']]\n",
      "        i = kb.factory.create(kb.Individual, conf).save()\n",
      "        by_label[r['IID']] = i\n",
      "        conf = {'study': study, 'individual': i, \n",
      "                'studyCode': r['IID']}\n",
      "        kb.factory.create(kb.Enrollment, conf).save()\n",
      "    return by_label"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rather than loading the whole dataset, we will now try with a small subset with only 10 individuals."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "study_label = 'ped_file_round_trip'\n",
      "\n",
      "reader = family_reader(10)\n",
      "\n",
      "study = kb.get_study(study_label)\n",
      "if study is None:\n",
      "    # we assume that if we do not have a study, we don't have the individuals.\n",
      "    study = kb.factory.create(kb.Study, {'label': study_label}).save()\n",
      "    action = kb.create_an_action()\n",
      "    by_label = load_family_in_biobank(action, study, reader)\n",
      "else:\n",
      "    by_label = dict([(e.studyCode, e.individual) for e in kb.get_enrolled(study)])\n",
      "    action = (by_label.values()[0]).action # hack !@@@@!!!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a marker set from the map info\n",
      "-------------------------------------\n",
      "\n",
      "Above we have resolved almost all markers defined in `map_fname` to a corresponding entry in `dbSNP139.db`. We now build an explicit Markers array using the information contained in `rs_extra_fname`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import uuid\n",
      "\n",
      "def add_genotype_data_sample(mset, action, probs, confs):\n",
      "    conf = {'label': uuid.uuid4().hex,\n",
      "            'status': kb.DataSampleStatus.USABLE,\n",
      "            'action': action,\n",
      "            'snpMarkersSet': mset}\n",
      "    sample = kb.factory.create(kb.GenotypeDataSample, conf).save()\n",
      "    kb.genomics.add_gdo_data_object(action, sample, probs, confs)\n",
      "    \n",
      "def convert_to_gdo(mset, ped_reader, rs_labels, by_label):   \n",
      "    for r in ped_reader:\n",
      "        probs, confs = convert_to_array(rs_labels, prob_profiles, r[1])\n",
      "        action = kb.create_an_action(target=by_label[r[0][1]])\n",
      "        add_genotype_data_sample(mset, action, probs, confs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 10\n",
      "label, maker, model, version = ('T2D_28102013', \n",
      "                                'ICL', 'Cogoni', 'v1_a')\n",
      "ped_reader = it.islice(PedReader(map_fname, ped_fname), N)\n",
      "mset = kb.genomics.get_markers_array(label)\n",
      "if mset is None:\n",
      "    stream = csv.DictReader(open(rs_extra_fname), delimiter='\\t')\n",
      "    mset = kb.genomics.create_markers_array(\n",
      "                 label, maker, model, version, stream, action)\n",
      "    convert_to_gdo(mset, ped_reader, ordered_rs_labels, by_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mapping againt a reference genome\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_support_nodes(mset, ped_reader):\n",
      "    pos_by_rs = dict([(x[1], (x[0], x[3])) for x in ped_reader.map_data])\n",
      "    rows = kb.genomics.get_markers_array_rows(mset)\n",
      "    return np.array([pos_by_rs[r['label']] for r in rows], \n",
      "                    kb.VariantCallSupport.NODES_DTYPE)\n",
      "\n",
      "def get_vcs(mset, ped_reader, ref_genome, action):\n",
      "    vcs_label = mset.label + '+' + ref_genome.label\n",
      "    vcs = kb.genomics.get_vcs_by_label(vcs_label)\n",
      "    if vcs is None:\n",
      "        print 'need to create'\n",
      "        nodes = create_support_nodes(mset, ped_reader)\n",
      "        vcs = kb.genomics.create_vcs(mset, ref_genome, nodes, action)\n",
      "        vcs.label = vcs_label\n",
      "        vcs.save()\n",
      "    return vcs\n",
      "\n",
      "def get_ref_genome(ref_gen_label, action):\n",
      "    ref_genome = kb.get_by_label(kb.ReferenceGenome, ref_gen_label)\n",
      "    if not ref_genome:\n",
      "        conf = {'nChroms' : 26, \n",
      "                'maker': 'GRC', 'model': 'h37', 'release' : '1',\n",
      "                'label': ref_gen_label,\n",
      "                'status' : kb.DataSampleStatus.USABLE,\n",
      "                'action': action}\n",
      "        ref_genome = kb.factory.create(kb.ReferenceGenome, conf).save()\n",
      "    return ref_genome"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref_gen_label = 'GRCh37.1'\n",
      "ped_reader = PedReader(map_fname, ped_fname)\n",
      "\n",
      "# we are re-using action because this is a mock-up\n",
      "# do not do it in real code!\n",
      "ref_genome = get_ref_genome(ref_gen_label, action)\n",
      "vcs = get_vcs(mset, ped_reader, ref_genome, action)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate pedfile\n",
      "----------------\n",
      "\n",
      "We will now output a pedfile with data restricted to the snp present in a given genome window."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcs_selected = vcs.selection(((20, 1), (20, 100000000)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(vcs_selected)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "7253"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "origin = vcs_selected.get_field('origin')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "origin[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "array([(0, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 267751),\n",
        "       (1, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 271709),\n",
        "       (2, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 270383),\n",
        "       (3, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 272679),\n",
        "       (4, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 272207),\n",
        "       (5, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 268017),\n",
        "       (6, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 270686),\n",
        "       (7, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 272876),\n",
        "       (8, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 272279),\n",
        "       (9, 'V0F7FE6C4E20A74AB8A0842EAE2FAB6B09', 272776)], \n",
        "      dtype=[('index', '<i8'), ('vid', 'S34'), ('vpos', '<i8')])"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_sample_by_id = dict(\n",
      "    [(e.individual.id, kb.get_data_samples(e.individual, data_sample_klass_name='GenotypeDataSample').next())\n",
      "     for e in kb.get_enrolled(study)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_sample_by_id"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "{'V008619632AEA84A6F9B74706FF91237FD': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5c50>,\n",
        " 'V021BCBAB83DDB434EBA08BE13A61810F3': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5cd0>,\n",
        " 'V035B10808A39444BB8D24272851FF931F': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5b50>,\n",
        " 'V035D1FC342B8C4CBF84F36C91A48FF4C2': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5c10>,\n",
        " 'V03FFE9BFD1C8949BF93AD83BDDC1FC2BB': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5bd0>,\n",
        " 'V048F6F08A875A4C3FB3DB40F993C3F2F0': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5c90>,\n",
        " 'V05E83E8EC323B40B08FEACB2FE01C370D': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5b90>,\n",
        " 'V05FA5FA4D55D441E7A9D1CC81F48B4612': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5b10>,\n",
        " 'V0D316159D68A443708DBEA5A25D7F8D90': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5ad0>,\n",
        " 'V0F46659C415AA4E57A1D00A0FC9139410': <bl.vl.kb.drivers.omero.data_samples.GenotypeDataSample at 0x899e5d10>}"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bl.vl.genotype.io import PedWriter\n",
      "ped_writer = PedWriter(vcs_selected, base_path='foo_ped')\n",
      "ped_writer.write_map()\n",
      "ped_writer.write_family(study.label, \n",
      "                        [e.individual for e in kb.get_enrolled(study)], \n",
      "                        data_sample_by_id=data_sample_by_id)\n",
      "ped_writer.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load pheno info as ehr records\n",
      "------------------------------\n",
      "\n",
      "The code below will associate phenotypical data to the individuals defined above. The data source is `pheno_fname`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pheno_reader(N=None):\n",
      "    reader = csv.DictReader(open(pheno_fname), delimiter='\\t')\n",
      "    return reader if N is None else it.islice(reader, 0, N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for r in pheno_reader(3):\n",
      "    print r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'Age': '47.3', 'BMI': '24', 'Father': '0', 'T2D': '1', 'Sex': '2', 'IID': '50010', 'FID': '1', 'Mother': '0'}\n",
        "{'Age': '47.27', 'BMI': '22.5', 'Father': '0', 'T2D': '1', 'Sex': '1', 'IID': '50013', 'FID': '2', 'Mother': '0'}\n",
        "{'Age': '46.38', 'BMI': '20.2', 'Father': '0', 'T2D': '1', 'Sex': '2', 'IID': '50023', 'FID': '4', 'Mother': '0'}\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have a problem. The phenotype data provided has an 'age' column, which is unclear if it is an age of onset of disease, or simply  the individual age when the sample was collected. For the time being, we will record only if the individual either has a diagnosis of diabetes of type 2 or not. In a later example we will consider BMI and age details."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DIAGNOSIS = 'openEHR-EHR-EVALUATION.problem-diagnosis.v1'\n",
      "DIAGNOSIS_TERM = 'at0002.1'\n",
      "DIABETES_TYPE_2 = 'icd10-cm:E11'\n",
      "DIAGNOSIS_AGE_AT_ONSET_TERM = 'at0004'\n",
      "\n",
      "#--\n",
      "EXCLUSION = 'openEHR-EHR-EVALUATION.exclusion-problem_diagnosis.v1'\n",
      "EXCLUSION_FIELD = 'at0002.1' # ????\n",
      "NO_SIGNIFICANT_MEDICAL_HISTORY = 'local:at0.3' # This is a LOCAL code\n",
      "\n",
      "import time\n",
      "def save_clinical_record(individual, archetype, fields):\n",
      "    # hack! Fill minimal timestamp and action just to get things going\n",
      "    timestamp = int(time.time() * 1000)\n",
      "    action = kb.create_an_action(target=individual).save()\n",
      "    kb.add_ehr_record(action, timestamp, archetype, fields)\n",
      "\n",
      "affected_code = '2'\n",
      "def save_clinical_records(reader, by_label):\n",
      "    for r in reader:\n",
      "        if r['IID'] in by_label:\n",
      "            if r['T2D'] == affected_code:\n",
      "                archetype = DIAGNOSIS\n",
      "                fields = {DIAGNOSIS_TERM: DIABETES_TYPE_2}\n",
      "            else:\n",
      "                archetype = EXCLUSION\n",
      "                fields = {EXCLUSION_FIELD: NO_SIGNIFICANT_MEDICAL_HISTORY}\n",
      "            save_clinical_record(by_label[r['IID']], archetype, fields)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for e in kb.get_enrolled(study):\n",
      "    assert e.individual == by_label[e.studyCode]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "save_clinical_records(pheno_reader(), by_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ehr = kb.get_ehr(by_label.values()[0])\n",
      "ehr.recs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 51,
       "text": [
        "{'openEHR-EHR-EVALUATION.exclusion-problem_diagnosis.v1': [{'a_id': 'V03480653A24064D2A964AFC9C86205C47',\n",
        "   'archetype': 'openEHR-EHR-EVALUATION.exclusion-problem_diagnosis.v1',\n",
        "   'fields': {'at0002.1': 'local:at0.3'},\n",
        "   'g_id': 'V0852551BD57E048D296568BF8027D4CEA',\n",
        "   'i_id': 'V0F46659C415AA4E57A1D00A0FC9139410',\n",
        "   'timestamp': 1386685757129,\n",
        "   'valid': 1}]}"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pheno_by_id = {}\n",
      "for k, i in by_label.iteritems():\n",
      "    ehr = kb.get_ehr(i)\n",
      "    pheno_by_id[i.id] = '2' if ehr.matches(archetype=DIAGNOSIS, \n",
      "                                           field=DIAGNOSIS_TERM, \n",
      "                                           value=DIABETES_TYPE_2) else '0'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ped_writer = PedWriter(vcs_selected, base_path='foo_ped_with_pheno')\n",
      "ped_writer.write_map()\n",
      "ped_writer.write_family(study.label, \n",
      "                        [e.individual for e in kb.get_enrolled(study)], \n",
      "                        data_sample_by_id=data_sample_by_id,\n",
      "                        phenotype_by_id=pheno_by_id)\n",
      "ped_writer.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Select a Cohort\n",
      "======================================\n",
      "\n",
      "This example describes how one can use vl to select a cohort of\n",
      "individuals.\n",
      "\n",
      "The basic idea is that the selected individuals, e.g.,\n",
      "by phenotype and age, are enrolled in an ad-hoc study.\n",
      "\n",
      "For instance, in this example, we will select an affected and a control\n",
      "group with the same proportion of male/female.\n",
      "\n",
      "FIXME extend example with age at onset.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DIAGNOSIS = 'openEHR-EHR-EVALUATION.problem-diagnosis.v1'\n",
      "DIAGNOSIS_TERM = 'at0002.1'\n",
      "DIABETES_TYPE_1 = 'icd10-cm:E10'\n",
      "#--\n",
      "EXCLUSION = 'openEHR-EHR-EVALUATION.exclusion-problem_diagnosis.v1'\n",
      "EXCLUSION_FIELD = 'at0002.1' # ????\n",
      "\n",
      " def get_ehr_iterator(self):\n",
      "    inds = self.kb.get_objects(self.kb.Individual)\n",
      "    inds_by_vid = dict([(i.id, i) for i in inds])\n",
      "    for e in self.kb.get_ehr_iterator():\n",
      "      if not e[0] in inds_by_vid:\n",
      "        #FIXME we need to do this for potential stray records left by testing\n",
      "        continue\n",
      "      yield (inds_by_vid[e[0]], e[1])\n",
      "   # A more sophisticated example\n",
      "    # will keep only records where age of onset is between 10y and 15y\n",
      "    # for i, ehr in self.get_ehr_iterator():\n",
      "    #   if (ehr.matches(DIAGNOSIS, DIAGNOSIS_TERM, DIABETES_TYPE_1)\n",
      "    #       and\n",
      "    #       ehr.matches(DIAGNOSIS, DIAGNOSIS_AGE_OF_ONSET, (\"10y\", \"15y\")):\n",
      "    #     affected.append(i)\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}