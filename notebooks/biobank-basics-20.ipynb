{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Loading genotyping data from a ped dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The goal of this example is to show how it is possible to load genotyping information held in the pedlink format into omero.biobank.\n",
      "\n",
      "We will first do some experiments with the data, just to understand its structure, and then we will build the appropriate omero.biobank objects.\n",
      "\n",
      "At the end of the exercise, we will show how to extract pedlink files on sub pedigrees and sub set of markers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Reading the original ped file\n",
      "-----------------------------\n",
      "\n",
      "Some text to describe it?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ped_fname='/var/tmp/T2D_28102013/T2D_28102013_CogoniQC.ped'\n",
      "map_fname='/var/tmp/T2D_28102013/T2D_28102013_CogoniQC.map'\n",
      "fam_fname='/var/tmp/T2D_28102013/T2D_28102013_CogoniQC.fam'\n",
      "pheno_fname='/var/tmp/T2D_28102013/T2DPheno_28102013.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will be using the ped reading utilities present in `bl/vl/genotype/io`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from bl.vl.genotype.io import MapReader, PedLineParser\n",
      "import csv\n",
      "\n",
      "class PedReader(object):\n",
      "    def __init__(self, map_fname, ped_fname):\n",
      "        self.map_data = [x for x in MapReader(open(map_fname))]\n",
      "        # we assume 1 column for affection status \n",
      "        # and then len(map_data) markers\n",
      "        dat_types = ['A'] + ['M'] * len(self.map_data)\n",
      "        self.pedline_parser = PedLineParser(dat_types)\n",
      "    def __iter__(self):\n",
      "        labels = [x[1] for x in self.map_data]\n",
      "        with open(ped_fname) as f:\n",
      "            for l in f:\n",
      "                data = self.pedline_parser.parse(l)\n",
      "                yield data[0:6], dict(zip(labels, data[6:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ped_reader = PedReader(map_fname, ped_fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, d in enumerate(ped_reader):\n",
      "    if i > 2:\n",
      "        break\n",
      "    print [(k, val) for k, val in d[1].iteritems()][:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('rs7060463', ['G', 'G']), ('rs4668795', ['A', 'A']), ('rs4072683', ['A', 'A'])]\n",
        "[('rs7060463', ['A', 'A']), ('rs4668795', ['C', 'C']), ('rs4072683', ['A', 'A'])]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('rs7060463', ['A', 'A']), ('rs4668795', ['A', 'A']), ('rs4072683', ['A', 'A'])]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next thing, we will check the rs codes against dbSNP139. This is done using an external program/galaxy application. FIXME it would be nice if we could directly invoke a workflow from here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rs_label_fname = '/var/tmp/rs_list.tsv'\n",
      "rs_extra_fname = '/var/tmp/rs_extracted.tsv'\n",
      "with open(rs_label_fname, 'w') as f:\n",
      "    writer = csv.DictWriter(f, fieldnames=['label'], delimiter='\\t')\n",
      "    writer.writeheader()\n",
      "    for r in ped_reader.map_data:\n",
      "        writer.writerow({'label': r[1]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# python ~/work/vs/git/biobank/tools/snp_manager manage_db --db-file dbSNP139.db \\\n",
      "#        --join rs_list.tsv > /var/tmp/extracted.tsv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_rs_labels(fname):\n",
      "    with open(fname) as f:\n",
      "        reader = csv.DictReader(f, delimiter='\\t')\n",
      "        rs_labels = [r['label'] for r in reader]\n",
      "    return rs_labels\n",
      "\n",
      "rs_list = set(read_rs_labels(rs_label_fname))\n",
      "rs_ext  = set(read_rs_labels(rs_extra_fname))\n",
      "len(rs_list), len(rs_ext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "(295667, 291634)"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears that only a subset of the rs labels actually exists in dbSNP139."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[x for x in (rs_list - rs_ext)][:4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "['rs9955474', 'rs6422346', 'rs7393468', 'rs7393469']"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML(\"\"\"<iframe src=http://www.ncbi.nlm.nih.gov/snp/?term=rs6422346 \n",
      "         width=1000 height=400></iframe>\"\"\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=http://www.ncbi.nlm.nih.gov/snp/?term=rs6422346 \n",
        "         width=1000 height=400></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<IPython.core.display.HTML at 0xd851a10>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One more thing, in `rs_extra_fname` we now have compact `absolute` markers definitions that we will use to define the marker array in omero.biobank."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import itertools as it"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(rs_extra_fname) as f:\n",
      "    for l in it.islice(f, 3):\n",
      "        print l,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "label\tmask\tindex\tpermutation\r\n",
        "rs549\tTATGAACTAAGCGGTGAGGCTCAGGTGGCGGCTCTCGCAGAGCCCCTGATGCTGTTGTTCTTTGAGGGCTTAAGGCCTGATGAACGTAGGCACGTGATGC[A/G]TAATAGTCTTCAATGGTACACTTAACTAGTCTCTTCTGTGTAACAGCAAAAAAAAAAAAAAAAAGAAGAAGAAAGAAAACTGTAGGAAATGTTCTTTTTG\t0\tFalse\r\n",
        "rs699\tTGGATACTAAGTCCTAGGGCCAGAGCCAGCAGAGAGGTTTGCCTTACCTTGGAAGTGGACGTAGGTGTTGAAAGCCAGGGTGCTGTCCACACTGGCTCCC[A/G]TCAGGGAGCAGCCAGTCTTCCATCCTGTCACAGCCTGCATGAACCTGTCAATCTTCTCAGCAGCAACATCCAGTTCTGTGAAGTCCAGAGAGCGTGGGAG\t1\tFalse\r\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The allele order in the mask defines what is the `A` and the `B` alleles. We now need to extract the proper allele order from the masks so that we can properly convert the genotyped values to probabilities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import bl.vl.utils.snp as snp_utils\n",
      "\n",
      "alleles_of_rs = {}\n",
      "ordered_rs_labels = []\n",
      "prob_profiles = []\n",
      "with open(rs_extra_fname) as f:\n",
      "    for r in csv.DictReader(f, delimiter='\\t'):\n",
      "        _, alleles, _ = snp_utils.split_mask(r['mask'])\n",
      "        alleles_of_rs[r['label']] = alleles\n",
      "        ordered_rs_labels.append(r['label'])\n",
      "        prob_profiles.append({(alleles[0], alleles[0]): [1, 0],\n",
      "                              (alleles[0], alleles[1]): [0, 0],\n",
      "                              (alleles[1], alleles[0]): [0, 0],\n",
      "                              (alleles[1], alleles[1]): [0, 1],\n",
      "                              ('0', '0'): [1/3., 1/3.]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "With this info we can now convert to the gdo (probability arrays) format. \n",
      "FIXME Note that we are setting the confidence to 0."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_to_array(rs_labels, prob_profiles, data):\n",
      "    N = len(rs_labels)\n",
      "    prob = np.zeros((2, N), dtype=np.float32)\n",
      "    conf = np.zeros((N,), dtype=np.float32)\n",
      "    for i in xrange(N):\n",
      "        prob[:,i] = prob_profiles[i][tuple(data[rs_labels[i]])]\n",
      "    return prob, conf\n",
      "\n",
      "ped_reader = PedReader(map_fname, ped_fname)\n",
      "\n",
      "for r in it.islice(ped_reader, 3):\n",
      "    prob, conf = convert_to_array(ordered_rs_labels, prob_profiles, r[1])\n",
      "    print prob[:,:10]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.  0.  0.  1.  1.  0.  1.  0.  0.  1.]\n",
        " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  0.]]\n",
        "[[ 1.  0.  0.  1.  0.  0.  0.  0.  1.  0.]\n",
        " [ 0.  1.  0.  0.  0.  0.  0.  1.  0.  0.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[[ 0.  1.  0.  1.  0.  0.  0.  1.  0.  0.]\n",
        " [ 0.  0.  1.  0.  0.  0.  1.  0.  1.  0.]]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now we are ready to upload data into biobank."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Talking to the back-end"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys, os\n",
      "from bl.vl.kb import KnowledgeBase\n",
      "\n",
      "OME_HOST = os.getenv('OME_HOST', 'localhost')\n",
      "OME_USER = os.getenv('OME_USER', 'test')\n",
      "OME_PASSWD = os.getenv('OME_PASSWD', 'test')\n",
      "CHECK_OME_VERSION = os.getenv('CHECK_OME_VERSION', \"True\") == \"True\"\n",
      "\n",
      "BaseProxy = KnowledgeBase(driver='omero')\n",
      "\n",
      "class Proxy(BaseProxy):\n",
      "  def get_objects_dict(self, klass):\n",
      "    return dict((o.label, o) for o in super(Proxy, self).get_objects(klass))\n",
      "\n",
      "kb = Proxy(OME_HOST, OME_USER, OME_PASSWD, check_ome_version=CHECK_OME_VERSION)\n",
      "kb.connect()\n",
      "kb.start_keep_alive()\n",
      "\n",
      "def cleanup():\n",
      "  print \"# disconnecting the kb\"\n",
      "  kb.disconnect()\n",
      "\n",
      "sys.exitfunc = cleanup\n",
      "\n",
      "print\n",
      "print \"### KB ENV PRELOADED ###\"\n",
      "print \"# connected to %s\" % OME_HOST\n",
      "print \"# knowledge base: kb\"\n",
      "print \"# extra method: kb.get_objects_dict\"\n",
      "print \"########################\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "### KB ENV PRELOADED ###\n",
        "# connected to biobank04.crs4.it\n",
        "# knowledge base: kb\n",
        "# extra method: kb.get_objects_dict\n",
        "########################\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load all the individuals and enroll them in a study"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the following, we will define a new set of individuals and enroll them in a study.\n",
      "Note that studyCode is the code assigned to each individual in a specific study.\n",
      "After the definition, we run a consistency check as follows.\n",
      "*NOTE:* this is not the fastest way to load individuals, see the FIXME importer code for a more efficient implementation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def family_reader(N=None):\n",
      "    fieldnames = ['FID', 'IID', 'Father', 'Mother', 'sex', 'T2D']\n",
      "    reader = csv.DictReader(open(fam_fname), fieldnames=fieldnames, delimiter='\\t')\n",
      "    return reader if N is None else it.islice(reader, 0, N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_family_in_biobank(action, study, reader):\n",
      "    gender_map = {'1': kb.Gender.MALE, '2': kb.Gender.FEMALE}\n",
      "    by_label = {}\n",
      "    for r in reader:\n",
      "        conf = {'gender': gender_map[r['sex']], 'action': action}\n",
      "        if r['Father'] != '0':\n",
      "            conf['father'] = by_label[r['Father']]\n",
      "        if r['Mother'] != '0':\n",
      "            conf['mother'] = by_label[r['Mother']]\n",
      "        i = kb.factory.create(kb.Individual, conf).save()\n",
      "        by_label[r['IID']] = i\n",
      "        conf = {'study': study, 'individual': i, \n",
      "                'studyCode': r['IID']}\n",
      "        kb.factory.create(kb.Enrollment, conf).save()\n",
      "    return by_label   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reader = family_reader(10)\n",
      "with kb.context.sandbox():\n",
      "    action = kb.create_an_action()\n",
      "    study = kb.factory.create(kb.Study, {'label': 'atest'}).save()\n",
      "    by_label = load_family_in_biobank(action, study, reader)\n",
      "    # minimal consistency check below\n",
      "    for e in kb.get_enrolled(study):\n",
      "        assert e.individual == by_label[e.studyCode]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load pheno info as ehr records\n",
      "------------------------------\n",
      "\n",
      "The code below will associate phenotypical data to the individuals defined above. The data source is `pheno_fname`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pheno_reader(N=None):\n",
      "    reader = csv.DictReader(open(pheno_fname), delimiter='\\t')\n",
      "    return reader if N is None else it.islice(reader, 0, N)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we have a major problem. The phenotype data provided has an 'age' column, which is unclear if it is an age of onset of disease, or simply  the individual age when the sample was collected.\n",
      "A way to handle this -- completely fake but it will generate the right data structure -- would be to:\n",
      "\n",
      "  1. associate a formal year of birth to the individual (which could be today - age);\n",
      "  2. associate an evaluation of diagnosis/exclusion for TD2 (done today);\n",
      "  3. associate an observation of BMI (done today);\n",
      "  4. associate a sample collection action (done today), \n",
      "     which results in a dna sample which will be then connected to the genotyping data;"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DIAGNOSIS = 'openEHR-EHR-EVALUATION.problem-diagnosis.v1'\n",
      "DIAGNOSIS_TERM = 'at0002.1'\n",
      "DIABETES_TYPE_2 = 'icd10-cm:E11'\n",
      "DIAGNOSIS_AGE_AT_ONSET_TERM = 'at0004'\n",
      "\n",
      "OBSERVATION = 'openEHR-EHR-OBSERVATION.body_mass_index.v1'\n",
      "OBSERVATION_BMI_TERM = 'at0004'\n",
      "\n",
      "#--\n",
      "EXCLUSION = 'openEHR-EHR-EVALUATION.exclusion-problem_diagnosis.v1'\n",
      "EXCLUSION_FIELD = 'at0002.1' # ????\n",
      "\n",
      "\n",
      "affected_code = '2'\n",
      "def save_clinical_records(pheno_reader, by_label):\n",
      "    for r in pheno_reader:\n",
      "        individual = by_label[r['IID']]\n",
      "        if r['TD'] == affected_code:\n",
      "            pass\n",
      "    FIXME\n",
      "            \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 3\n",
      "with kb.context.sandbox():\n",
      "    action = kb.create_an_action()\n",
      "    study = kb.factory.create(kb.Study, {'label': 'atest'}).save()\n",
      "    by_label = load_family_in_biobank(action, study, family_reader(N))\n",
      "    # minimal consistency check below\n",
      "    for e in kb.get_enrolled(study):\n",
      "        assert e.individual == by_label[e.studyCode]\n",
      "    save_clinical_records(pheno_reader(N), by_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'save_ehr_records' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-20-133a3fcd3c22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enrolled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindividual\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mby_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstudyCode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msave_ehr_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpheno_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'save_ehr_records' is not defined"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a marker set from the map info\n",
      "-------------------------------------\n",
      "\n",
      "Above we have resolved almost all markers defined in `map_fname` to a corresponding entry in `dbSNP139.db`. We now build an explicit Markers array using the information contained in `rs_extra_fname`. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_marker_array():\n",
      "    label, maker, model, version = ('T2D_28102013', \n",
      "                                    'ICL', 'Cogoni', 'v1_a')\n",
      "    mset = kb.genomics.get_markers_array(label)\n",
      "    if mset is None:\n",
      "        stream = csv.DictReader(open(rs_extra_fname), delimiter='\\t')\n",
      "        mset = kb.genomics.create_markers_array(\n",
      "                 label, maker, model, version, stream, action)\n",
      "    return mset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import uuid\n",
      "\n",
      "def add_genotype_data_sample(mset, action, probs, confs):\n",
      "    conf = {'label': uuid.uuid4().hex,\n",
      "            'status': kb.DataSampleStatus.USABLE,\n",
      "            'action': action,\n",
      "            'snpMarkersSet': mset}\n",
      "    sample = kb.factory.create(kb.GenotypeDataSample, conf).save()\n",
      "    kb.genomics.add_gdo_data_object(action, sample, probs, confs)\n",
      "    \n",
      "def convert_to_gdo(mset, ped_reader, rs_labels, by_label):   \n",
      "    for r in ped_reader:\n",
      "        probs, confs = convert_to_array(rs_labels, prob_profiles, r[1])\n",
      "        action = kb.create_an_action(target=by_label[r[0][1]])\n",
      "        add_genotype_data_sample(mset, action, probs, confs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N = 3\n",
      "ped_reader = it.islice(PedReader(map_fname, ped_fname), N)\n",
      "with kb.context.sandbox():\n",
      "    mset = create_marker_array()\n",
      "    action = kb.create_an_action()\n",
      "    study = kb.factory.create(kb.Study, {'label': 'atest'}).save()\n",
      "    by_label = load_family_in_biobank(action, study, family_reader(N))\n",
      "    convert_to_gdo(mset, ped_reader, ordered_rs_labels, by_label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mapping againt a reference genome\n",
      "---------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_support_nodes(mset, ped_reader):\n",
      "    pos_by_rs = dict([(x[1], (x[0], x[3])) for x in ped_reader.map_data])\n",
      "    rows = kb.genomics.get_markers_array_rows(mset)\n",
      "    return np.array([pos_by_rs[r['label']] for r in rows], \n",
      "                    kb.VariantCallSupport.NODES_DTYPE)\n",
      "\n",
      "def get_vcs(mset, ped_reader, ref_genome, action):\n",
      "    vcs_label = mset.label + '+' + ref_genome.label\n",
      "    vcs = kb.genomics.get_vcs_by_label(vcs_label)\n",
      "    if vcs is None:\n",
      "        print 'need to create'\n",
      "        nodes = create_support_nodes(mset, ped_reader)\n",
      "        vcs = kb.genomics.create_vcs(mset, ref_genome, nodes, action)\n",
      "        vcs.label = vcs_label\n",
      "        vcs.save()\n",
      "    return vcs\n",
      "\n",
      "def get_ref_genome(ref_gen_label, action):\n",
      "    ref_genome = kb.get_by_label(kb.ReferenceGenome, ref_gen_label)\n",
      "    if not ref_genome:\n",
      "        conf = {'nChroms' : 26, \n",
      "                'maker': 'GRC', 'model': 'h37', 'release' : '1',\n",
      "                'label': ref_gen_label,\n",
      "                'status' : kb.DataSampleStatus.USABLE,\n",
      "                'action': action}\n",
      "        ref_genome = kb.factory.create(kb.ReferenceGenome, conf).save()\n",
      "    return ref_genome"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref_gen_label = 'GRCh37.1'\n",
      "ped_reader = PedReader(map_fname, ped_fname)\n",
      "\n",
      "# we are re-using action because this is a mock-up\n",
      "# do not do it in real code!\n",
      "with kb.context.sandbox():\n",
      "    mset = create_marker_array()\n",
      "    action = kb.create_an_action()\n",
      "    ref_genome = get_ref_genome(ref_gen_label, action)\n",
      "    vcs = get_vcs(mset, ped_reader, ref_genome, action)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Select a Cohort\n",
      "======================================\n",
      "\n",
      "This example describes how one can use vl to select a cohort of\n",
      "individuals.\n",
      "\n",
      "The basic idea is that the selected individuals, e.g.,\n",
      "by phenotype and age, are enrolled in an ad-hoc study.\n",
      "\n",
      "For instance, in this example, we will select an affected and a control\n",
      "group with the same proportion of male/female.\n",
      "\n",
      "FIXME extend example with age at onset.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DIAGNOSIS = 'openEHR-EHR-EVALUATION.problem-diagnosis.v1'\n",
      "DIAGNOSIS_TERM = 'at0002.1'\n",
      "DIABETES_TYPE_1 = 'icd10-cm:E10'\n",
      "#--\n",
      "EXCLUSION = 'openEHR-EHR-EVALUATION.exclusion-problem_diagnosis.v1'\n",
      "EXCLUSION_FIELD = 'at0002.1' # ????\n",
      "\n",
      " def get_ehr_iterator(self):\n",
      "    inds = self.kb.get_objects(self.kb.Individual)\n",
      "    inds_by_vid = dict([(i.id, i) for i in inds])\n",
      "    for e in self.kb.get_ehr_iterator():\n",
      "      if not e[0] in inds_by_vid:\n",
      "        #FIXME we need to do this for potential stray records left by testing\n",
      "        continue\n",
      "      yield (inds_by_vid[e[0]], e[1])\n",
      "   # A more sophisticated example\n",
      "    # will keep only records where age of onset is between 10y and 15y\n",
      "    # for i, ehr in self.get_ehr_iterator():\n",
      "    #   if (ehr.matches(DIAGNOSIS, DIAGNOSIS_TERM, DIABETES_TYPE_1)\n",
      "    #       and\n",
      "    #       ehr.matches(DIAGNOSIS, DIAGNOSIS_AGE_OF_ONSET, (\"10y\", \"15y\")):\n",
      "    #     affected.append(i)\n",
      "\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}