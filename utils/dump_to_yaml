#!/usr/bin/env python

import argparse, sys, csv

from bl.vl.kb import KnowledgeBase as KB
from bl.vl.kb.mimetypes import GDO_TABLE
from bl.vl.kb.serialize.yaml_serializer import YamlSerializer
from bl.vl.utils import LOG_LEVELS, get_logger


def make_parser():
    parser = argparse.ArgumentParser('Dump all data related to a specific user from an OMERO server to a YAML file')
    parser.add_argument('--logfile', type=str, help='log file (default=stderr)')
    parser.add_argument('--loglevel', type=str, choices=LOG_LEVELS,
                        help='logging level', default='INFO')
    parser.add_argument('--host', '-H', type=str, help='OMERO host',
                        required=True)
    parser.add_argument('--user', '-U', type=str, help='OMERO user',
                        required=True)
    parser.add_argument('--passwd', '-P', type=str, help='OMERO password',
                        required=True)
    parser.add_argument('--out-file', '-O', type=str, help='YAML output file',
                        required=True)
    parser.add_argument('--dependencies-file', '-D', type=str, required=True,
                        help='TSV file used to store dependencies (objects in the public pool not owned by the current user)')
    parser.add_argument('--public-objects-file', '-p', type=str, required=True,
                        help='TSV file with a list of the objects of the current user that are stored in the public pool')
    parser.add_argument('--exclude-types', type=str, default='',
                        help='A list of comma separated types that will be exclude from the dump process')
    parser.add_argument('--exclude-gdos', action='store_true',
                        help='exclude GDOs serialized as OMERO.table rows')
    parser.add_argument('--export-omero-tables', action='store_true',
                        help='export OMERO.tables definitions')
    return parser


def get_data_objects(kb, logger, exclude_gdos):
    if exclude_gdos:
        logger.info('Retrieving DataObjects. GDOs excluded')
        query = 'SELECT dobj FROM DataObject dobj WHERE dobj.mimetype != :mtype'
        return kb.find_all_by_query(query, {'mtype': GDO_TABLE})
    else:
        logger.info('Retrieving DataObjects')
        return kb.get_objects(kb.DataObject)


def get_omero_tables(kb, logger):
    query = 'SELECT ofile FROM OriginalFile ofile WHERE ofile.mimetype = :tables_mtype'
    tables = kb.find_all_by_query(query, {'tables_mtype': 'OMERO.tables'})
    logger.info('Retrieved %d OMERO.tables', len(tables))
    return tables


def get_all_objects(kb, exclude_gdos, excluded_types, logger):
    obj_classes = [kb.Individual, kb.Enrollment, kb.Vessel,
                   kb.Study, kb.Device, kb.DataSample,
                   kb.VLCollection, kb.DataCollectionItem,
                   kb.VesselsCollectionItem, kb.LaneSlot]
    logger.info('Loading data')
    objects = []
    for o in obj_classes:
        if o.__name__ not in excluded_types:
            logger.info('Loading %s', o.__name__)
            objects.extend(kb.get_objects(o))
    objects.extend(get_data_objects(kb, logger, exclude_gdos))
    return objects


def to_yaml(outfile, deps_file, public_objs_file, objects, kb, logger):
    def save_dependency(writer, obj, kb):
        writer.writerow({
            'class': obj.OME_TABLE,
            'id': obj.id,
            'owner': kb.get_object_owner(obj),
            'group': kb.get_object_group(obj)
        })

    logger.info('Serializing %d objects to %s', len(objects), outfile)
    # Fetch Actions and their ActionSetup in order to speedup serialization.
    # If a memory error occurs (Ice::MemoryLimitExcpetion) stop loading the cache.
    try:
        act_cache = kb.get_objects(kb.Action)
        acts_cache = kb.get_objects(kb.ActionSetup)
    except:
        pass
    with open(outfile, 'w') as f, open(deps_file, 'w') as df, open(public_objs_file, 'w') as pf:
        dep_writer = csv.DictWriter(df, ['class', 'id', 'owner', 'group'], delimiter='\t')
        dep_writer.writeheader()
        pub_writer = csv.DictWriter(pf, ['class', 'id'], delimiter='\t')
        pub_writer.writeheader()
        serializer = YamlSerializer(f, logger)
        for o in objects:
            if o.in_current_sandbox():
                o.serialize(serializer)
                if kb.get_object_group(o) == 'user':
                    pub_writer.writerow({
                        'class': o.OME_TABLE,
                        'id': o.id
                    })
            else:
                save_dependency(dep_writer, o, kb)
    logger.info('Objects serialization completed')


def dump_tables_description(outfile, kb, logger):
    logger.info('Dumping OMERO.tables details')
    with open(outfile, 'w') as ofile:
        tables_writer = csv.DictWriter(ofile, ['table_name', 'old_id'], delimiter='\t')
        tables_writer.writeheader()
        tables = get_omero_tables(kb, logger)
        for t in tables:
            tables_writer.writerow({'table_name': t.name, 'old_id': t.omero_id})


def main(argv):
    parser = make_parser()
    args = parser.parse_args(argv)

    logger = get_logger('main', level=args.loglevel, filename=args.logfile)
    kb = KB(driver='omero')(args.host, args.user, args.passwd)

    objects = get_all_objects(kb, args.exclude_gdos, args.exclude_types.split(','),
                              logger)
    to_yaml(args.out_file, args.dependencies_file, args.public_objects_file,
            objects, kb, logger)
    if args.export_omero_tables:
        tables_fname = '%s.tables' % args.out_file
        dump_tables_description(tables_fname, kb, logger)


if __name__ == '__main__':
    main(sys.argv[1:])
