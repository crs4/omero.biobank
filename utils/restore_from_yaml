#!/usr/bin/env python

import sys, gc, os
from yaml import CBaseLoader
from argparse import ArgumentError, ArgumentParser

from bl.vl.kb import KnowledgeBase as KB
from bl.vl.kb import KBError
from bl.vl.kb.serialize.deserialize import ObjectsLimbo
from bl.vl.utils import LOG_LEVELS, get_logger


def make_parser():
    parser = ArgumentParser('Restore data stored as YAML to an OMERO server')
    parser.add_argument('--logfile', type=str, help='log file (default=stderr)')
    parser.add_argument('--loglevel', type=str, choices=LOG_LEVELS,
                        help='logging level', default='INFO')
    parser.add_argument('--host', '-H', type=str, help='OMERO host',
                        required=True)
    parser.add_argument('--user', '-U', type=str, help='OMERO user',
                        required=True)
    parser.add_argument('--passwd', '-P', type=str, help='OMERO password',
                        required=True)
    parser.add_argument('--yaml-file', '-Y', type=str, help='YAML input file')
    parser.add_argument('--chunks-directory', '-D', type=str,
                        help='directory containing YAML chunks produced using the split_yaml_dump tool')
    return parser


def objects_from_yaml(kb, yaml_file, logger):
    logger.info('Loading objects from %s', yaml_file)
    limbo = ObjectsLimbo(kb, logger)
    with open(yaml_file) as f:
        loader = CBaseLoader(f)
        yaml_data = loader.get_data()
        loader.dispose()
        for ref, conf in yaml_data.iteritems():
            limbo.add_object(ref, conf)
        del yaml_data
        gc.collect()
    return limbo


def records_by_chunk(records, batch_size=500):
    offset = 0
    while len(records[offset:]) > 0:
        yield records[offset:offset+batch_size]
        offset += batch_size


def save_objects(kb, objects, logger):
    kb.connect()
    logger.info('Saving %d records', len(objects))
    for chunk, records in enumerate(records_by_chunk(objects)):
        logger.debug('Saving chunk %d', chunk)
        kb.save_array(records)
    kb.disconnect()


# Some objects like Studies and Devices can be shared in the biobank, handle them properly
def save_shared_objects(kb, objects, logger):
    kb.connect()
    for o in objects:
        try:
            o.save()
        except KBError, kerr:
            logger.debug('Object %s::%s already exists, ignoring',
                         o.__class__.__name__, o.id)
    kb.disconnect()


def to_biobank(kb, objects_limbo, logger):
    def get_base_klass(objtype):
        import omero
        import omero.model
        klass = getattr(omero.model, objtype)
        for i, k in enumerate(getattr(omero.model, objtype).__mro__):
            if k is omero.model.IObject:
                try:
                    klass = getattr(omero.model, objtype).__mro__[i-1]
                except IndexError:
                    pass
        return klass.__name__
    shared_objects_type = ['Study', 'Device']
    for objtype, objects in objects_limbo.groupbytype():
        logger.info('Saving type %s', objtype)
        bb_objs = [o[1] for o in objects]
        if get_base_klass(objtype) in shared_objects_type:
            save_shared_objects(kb, bb_objs, logger)
        else:
            save_objects(kb, bb_objs, logger)
    logger.info('Objects restoring completed')


def dump_file(kb, file_path, logger):
    objects_limbo = objects_from_yaml(kb, file_path, logger)
    to_biobank(kb, objects_limbo, logger)


def dump_chunks(kb, chunks_folder, logger):
    files = os.listdir(chunks_folder)
    files.sort()
    for f in files:
        dump_file(kb, os.path.join(chunks_folder, f), logger)
        os.remove(os.path.join(chunks_folder, f))


def main(argv):
    parser = make_parser()
    args = parser.parse_args(argv)

    logger = get_logger('restore_from_yaml', level=args.loglevel, filename=args.logfile)
    kb = KB(driver='omero')(args.host, args.user, args.passwd)
    kb.disconnect()

    if not args.yaml_file and not args.chunks_directory:
        raise ArgumentError('Provide a YAML file or a directory containing chunks')
    if args.yaml_file and args.chunks_directory:
        raise ArgumentError('Provide only one between YAML file and chunks directory')

    try:
        if args.yaml_file:
            dump_file(kb, args.yaml_file, logger)
        if args.chunks_directory:
            dump_chunks(kb, args.chunks_directory, logger)
    except Exception, e:
        logger.critical(e.message)

if __name__ == '__main__':
    main(sys.argv[1:])